# -*- coding: utf-8 -*-
"""Copy of FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14j-3-jgSv4YBLPKFuHdUA1zyk7lhK_20
"""

from google.colab import files
uploaded = files.upload()

#importing all the necessary libraries
import pandas as pd
import numpy as np
import nltk
import re
import seaborn
import csv
from tqdm import tqdm
import json
import seaborn as sns
import matplotlib.pyplot as plt 
import datetime

#loading the data
meta=pd.read_csv("movie.metadata.tsv",sep='\t',header=None)

meta.head()

#rename the columns
meta.columns=["movie_id",1,"movie_name","date",4,5,6,7,"genre"]

meta.head()

plots=[]
with open("plot_summaries.txt",'r') as f:
  reader=csv.reader(f,dialect='excel-tab')
  for row in tqdm(reader):
    plots.append(row)

movie_id=[]
plot=[]
for i in tqdm(plots):
  movie_id.append(i[0])
  plot.append(i[1])

movies=pd.DataFrame({'movie_id':movie_id,'plot':plot})

movies.head()

# change datatype of 'movie_id'
meta['movie_id'] = meta['movie_id'].astype(str)

# merge meta with movies
movies = pd.merge(movies, meta[['movie_id', 'movie_name','date', 'genre']], on = 'movie_id')

movies.head()

movies['genre'][0]

type(json.loads(movies['genre'][0]))

json.loads(movies['genre'][0]).values()

# an empty list
genres = [] 

# extract genres
for i in movies['genre']: 
  genres.append(list(json.loads(i).values())) 

# add to 'movies' dataframe  
movies['genre_new'] = genres

# remove samples with 0 genre tags
movies_new = movies[~(movies['genre_new'].str.len() == 0)]

movies_new.shape, movies.shape

movies.head()

all_genres = sum(genres,[])
len(set(all_genres))

all_genres = nltk.FreqDist(all_genres) 

# create dataframe
all_genres_df = pd.DataFrame({'Genre': list(all_genres.keys()), 
                              'Count': list(all_genres.values())})

g = all_genres_df.nlargest(columns="Count", n = 50) 
plt.figure(figsize=(12,15)) 
ax = sns.barplot(data=g, x= "Count", y = "Genre") 
ax.set(ylabel = 'Count') 
plt.show()

# function for text cleaning 
def clean_text(text):
    # remove backslash-apostrophe 
    text = re.sub("\'", "", text) 
    # remove everything except alphabets 
    text = re.sub("[^a-zA-Z]"," ",text) 
    # remove whitespaces 
    text = ' '.join(text.split()) 
    # convert text to lowercase 
    text = text.lower() 
    
    return text

movies_new['clean_plot'] = movies_new['plot'].apply(lambda x: clean_text(x))

movies_new.head()

def freq_words(x, terms = 30): 
  all_words = ' '.join([text for text in x]) 
  all_words = all_words.split() 
  fdist = nltk.FreqDist(all_words) 
  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())}) 
  
  # selecting top 20 most frequent words 
  d = words_df.nlargest(columns="count", n = terms) 
  
  # visualize words and frequencies
  plt.figure(figsize=(12,15)) 
  ax = sns.barplot(data=d, x= "count", y = "word") 
  ax.set(ylabel = 'Word') 
  plt.show()
  
# print 100 most frequent words 
freq_words(movies_new['clean_plot'], 100)

movies_new.head()

movies_new['year'] = movies_new['date'].str[:4]
movies_new.head()

movies_new.drop(['date','plot','genre'], axis=1)

import nltk.tokenize as nt
nltk.download('punkt')

nltk.download('averaged_perceptron_tagger')

from nltk import word_tokenize, pos_tag, pos_tag_sents


text=movies_new['clean_plot'].tolist()

tagged_texts = pos_tag_sents(map(word_tokenize, text))

tagged_texts

movies_new['grammatical Desciption'] = pos_tag_sents( movies_new['clean_plot'].apply(word_tokenize).tolist() )

movies_new.head()

movies=movies_new.drop(['date','plot','genre'], axis=1)

movies.head()

from google.colab import files
movies.to_csv('movies.csv') 
files.download('movies.csv')




